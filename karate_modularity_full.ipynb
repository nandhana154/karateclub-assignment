import networkx as nx
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from collections import defaultdict, deque

print('imports OK')

def compute_modularity_matrix(G, nodes=None):
    if nodes is None:
        nodes = list(G.nodes())
    node_index = {node:i for i,node in enumerate(nodes)}
    n = len(nodes)
    A = np.zeros((n,n), dtype=float)
    for i,u in enumerate(nodes):
        for v in G[u]:
            if v in node_index:
                A[i,node_index[v]] = 1.0
    full_k = np.array([G.degree(node) for node in nodes], dtype=float)
    m = G.number_of_edges()
    kkT = np.outer(full_k, full_k) / (2.0*m)
    B = A - kkT
    return B, nodes, full_k, m

def leading_eigenpair(B):
    vals, vecs = np.linalg.eigh(B)
    idx = np.argsort(vals)[::-1]
    return float(vals[idx[0]]), vecs[:, idx[0]]

def partition_from_eigenvector(nodes, leading_vec):
    plus = [nodes[i] for i,v in enumerate(leading_vec) if v>0]
    minus = [nodes[i] for i,v in enumerate(leading_vec) if v<=0]
    return plus, minus

def recursive_bisection(G, stop_when_nonpositive=True, visualize=True, layout=pos):

    assignment = {n:0 for n in G.nodes()}
    history = []

    def compute_metrics(iteration):
        deg = nx.degree_centrality(G)
        bet = nx.betweenness_centrality(G, normalized=True)
        clo = nx.closeness_centrality(G)
        clu = nx.clustering(G)

        df = pd.DataFrame({
            'node': list(G.nodes()),
            'degree': [deg[n] for n in G.nodes()],
            'betweenness': [bet[n] for n in G.nodes()],
            'closeness': [clo[n] for n in G.nodes()],
            'clustering': [clu[n] for n in G.nodes()],
            'community': [assignment[n] for n in G.nodes()],
            'iteration': iteration
        })
        return {'degree':deg,'betweenness':bet,'closeness':clo,'clustering':clu}, df


    iteration = 0
    metrics, df0 = compute_metrics(iteration)
    history.append({'iteration':iteration, 'communities':[set(G.nodes())], 'assignment':assignment.copy(), 'metrics_df':df0})

    
    import os
    os.makedirs("figures", exist_ok=True)


    from collections import defaultdict, deque
    q = deque()
    q.append((set(G.nodes()), 0))

    while q:
        C, cid = q.popleft()
        nodes = list(C)

        if len(nodes) <= 1:
            continue

        Bc, node_order, _, _ = compute_modularity_matrix(G, nodes=nodes)
        leading_val, leading_vec = leading_eigenpair(Bc)

        if stop_when_nonpositive and leading_val <= 0:
            continue

        plus, minus = partition_from_eigenvector(node_order, leading_vec)
        if len(plus) == 0 or len(minus) == 0:
            continue

        new_cid = max(assignment.values()) + 1

        for n in plus:
            assignment[n] = cid
        for n in minus:
            assignment[n] = new_cid

        community_sets = defaultdict(set)
        for n, c in assignment.items():
            community_sets[c].add(n)

        iteration += 1
        metrics, df_iter = compute_metrics(iteration)
        history.append({'iteration':iteration, 'communities':[set(s) for s in community_sets.values()],
                        'assignment':assignment.copy(), 'metrics_df':df_iter})


        if visualize:
            plt.figure(figsize=(6,4))
            node_colors = [assignment[n] for n in G.nodes()]

            nx.draw_networkx(G, pos=layout, with_labels=True,
                             node_color=node_colors, node_size=300)

            plt.title(f"Iteration {iteration}: {len(community_sets)} communities")
            plt.axis("off")

            # SAVE IMAGE
            plt.savefig(f"figures/iteration_{iteration}.png", dpi=300, bbox_inches="tight")
            plt.show()

    return list(community_sets.values()), history, assignment

G = nx.karate_club_graph()
pos = nx.spring_layout(G, seed=42)
communities, history, assignment = recursive_bisection(G, stop_when_nonpositive=True, visualize=True, layout=pos)
print(f'Found {len(communities)} communities:')
for i,c in enumerate(communities):
    print(f'Community {i} (size {len(c)}): {sorted(c)}')
plt.figure(figsize=(7,5))
node_colors = [assignment[n] for n in G.nodes()]
nx.draw_networkx(G, pos=pos, with_labels=True, node_color=node_colors, node_size=320)
plt.title(f'Final partition into {len(communities)} communities')
plt.axis('off')
plt.show()

df_all = pd.concat([h['metrics_df'] for h in history], ignore_index=True)
metrics = ['degree','betweenness','closeness','clustering']
for metric in metrics:
    plt.figure(figsize=(10,5))
    for node in sorted(G.nodes()):
        node_series = df_all[df_all['node']==node].sort_values('iteration')[metric].values
        iterations = df_all[df_all['node']==node].sort_values('iteration')['iteration'].values
        plt.plot(iterations, node_series, label=str(node), linewidth=1)
    plt.xlabel('Iteration')
    plt.ylabel(metric)
    plt.title(f'Evolution of {metric} across iterations (per node)')
    plt.legend(loc='center left', bbox_to_anchor=(1.0,0.5), ncol=1, fontsize='small')
    plt.tight_layout()
    plt.show()
from networkx.algorithms.community.quality import modularity
communities_list = [set(c) for c in communities]
Q = modularity(G, communities_list)
print(f'Modularity Q of final partition: {Q:.4f}')
